{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Imports\n",
    "---"
   ],
   "id": "308e71c660a7ab23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:08:21.225548Z",
     "start_time": "2025-04-13T14:08:17.349298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.agent_toolkits.json.toolkit import JsonToolkit\n",
    "from langchain_community.agent_toolkits.json.base import create_json_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "import json"
   ],
   "id": "48fe2553ab822baf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Load a large language model\n",
    "----------\n",
    "Langchain makes it possible to easily switch LLMs. Llama 3 is used to show the data can be analysed with a locally running open-source model, but it is very slow (because it runs on a notebook). So to speed it up I also used o3-mini to show it works.\n",
    "\n",
    "Load Llama3:\n"
   ],
   "id": "b05e975155a0d7e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T13:40:38.163145Z",
     "start_time": "2025-04-13T13:40:38.068810Z"
    }
   },
   "cell_type": "code",
   "source": "chosen_llm = ChatOllama(base_url='http://localhost:11434', model=\"llama3\")",
   "id": "a1a4046e1a641a9b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load o3-mini (via Azure):",
   "id": "f77781c99b48898a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:08:42.614337Z",
     "start_time": "2025-04-13T14:08:42.534252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "chosen_llm = AzureChatOpenAI(model =\"o3-mini\", api_version=\"2025-01-01-preview\", azure_endpoint=\"https://56948-m9bdjgpg-eastus2.cognitiveservices.azure.com/openai/deployments/o3-mini/chat/completions?api-version=2025-01-01-preview\", api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"))"
   ],
   "id": "dae3e6325e0ba1a2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Retrieve dataset\n",
    "---\n",
    "Here the dataset is retrieved and stored in a file."
   ],
   "id": "75f2763c0ba578b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:08:50.349319Z",
     "start_time": "2025-04-13T14:08:49.305004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = requests.get('https://data.rivm.nl/geo/ank/ows?service=WFS&request=GetFeature&typeName=rivm_2022_groenpercentage_kaart_per_buurt&propertyName=bu_naam,_mean&outputFormat=json').json()\n",
    "\n",
    "# Print dataset to file to inspect it when needed\n",
    "with open('groenPercentagePerBuurt.json', 'w') as file:\n",
    "    json.dump(dataset, file)"
   ],
   "id": "f6a843eb4896fce0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Extract properties\n",
    "---\n",
    "Not used anymore, when sending only the properties the agent couldn't understand the context of the data anymore. This resulted in getting the response \"I don't know\" constantly."
   ],
   "id": "592f7fc66d6cd554"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "properties = []\n",
    "neighborhoodGreenery = {}\n",
    "\n",
    "for feature in dataset[\"features\"]:\n",
    "    properties.append(feature[\"properties\"])\n",
    "\n",
    "for property in properties:\n",
    "    neighborhoodGreenery[property[\"bu_naam\"]] = property[\"_mean\"]"
   ],
   "id": "d7d0c7bcb5139f73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create and run the agent\n",
    "---\n",
    "Here the toolkit is created that \"gives\" the dataset to the agent. It also creates the agent itself, what will analyse the dataset when it is executed.\n"
   ],
   "id": "f4fc9eec4fd9d2bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:08:59.993688Z",
     "start_time": "2025-04-13T14:08:59.086817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create toolkit:\n",
    "json_spec = JsonSpec(dict_=dataset, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "# Create JSON agent\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=chosen_llm,\n",
    "    toolkit=json_toolkit,\n",
    "    verbose=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "input_text = \"Can you find out what the neighborhood Binnenstad-Noord has as _mean?\"\n",
    "response = json_agent_executor.invoke(input_text)"
   ],
   "id": "15fa21b9639e94f4",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
